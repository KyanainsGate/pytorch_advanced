{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZaLsEIeL8J7"
   },
   "source": [
    "# 6.4 Efficient GANの作成\n",
    "\n",
    "- 本ファイルでは、Efficient GANのネットワークを実装し、学習をします。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ey6RtLORL8KI"
   },
   "source": [
    "# 6.4 学習目標\n",
    "\n",
    "1.\tEfficient GANを実装し、手書き数字画像で異常検知が生成できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNnV0rM1L8KK"
   },
   "source": [
    "# 事前準備\n",
    "書籍の指示に従い、本章で使用するデータを用意します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lGX1rk4L8KL"
   },
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKc25TAjL8KP"
   },
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlfVYAe2L8KR"
   },
   "source": [
    "# Generatorの実装\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68sd3hevL8KS"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(z_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(1024, 7*7*128),\n",
    "            nn.BatchNorm1d(7*7*128),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=1,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh())\n",
    "        # 注意：白黒画像なので出力チャネルは1つだけ\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.layer1(z)\n",
    "        out = self.layer2(out)\n",
    "\n",
    "        # 転置畳み込み層に入れるためにテンソルの形を整形\n",
    "        out = out.view(z.shape[0], 128, 7, 7)\n",
    "        out = self.layer3(out)\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWygUNjSL8KU",
    "outputId": "71e4bf9e-abf8-497f-f265-910f83e7d4ae"
   },
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = Generator(z_dim=20)\n",
    "G.train()\n",
    "\n",
    "# 入力する乱数\n",
    "# バッチノーマライゼーションがあるのでミニバッチ数は2以上\n",
    "input_z = torch.randn(2, 20)\n",
    "\n",
    "# 偽画像を出力\n",
    "fake_images = G(input_z)  # torch.Size([2, 1, 28, 28])\n",
    "img_transformed = fake_images[0][0].detach().numpy()\n",
    "plt.imshow(img_transformed, 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIyWxLJPL8KW"
   },
   "source": [
    "# Discriminatorの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ug0Iof6uL8KX"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # 画像側の入力処理\n",
    "        self.x_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        # 注意：白黒画像なので入力チャネルは1つだけ\n",
    "\n",
    "        self.x_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        # 乱数側の入力処理\n",
    "        self.z_layer1 = nn.Linear(z_dim, 512)\n",
    "\n",
    "        # 最後の判定\n",
    "        self.last1 = nn.Sequential(\n",
    "            nn.Linear(3648, 1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.last2 = nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, x, z):\n",
    "\n",
    "        # 画像側の入力処理\n",
    "        x_out = self.x_layer1(x)\n",
    "        x_out = self.x_layer2(x_out)\n",
    "\n",
    "        # 乱数側の入力処理\n",
    "        z = z.view(z.shape[0], -1)\n",
    "        z_out = self.z_layer1(z)\n",
    "\n",
    "        # x_outとz_outを結合し、全結合層で判定\n",
    "        x_out = x_out.view(-1, 64 * 7 * 7)\n",
    "        out = torch.cat([x_out, z_out], dim=1)\n",
    "        out = self.last1(out)\n",
    "\n",
    "        feature = out  # 最後にチャネルを1つに集約する手前の情報\n",
    "        feature = feature.view(feature.size()[0], -1)  # 2次元に変換\n",
    "\n",
    "        out = self.last2(out)\n",
    "\n",
    "        return out, feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsKNLk4BL8Ka",
    "outputId": "072f54ca-2b19-486c-ef56-1ad9f2f24a91"
   },
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "D = Discriminator(z_dim=20)\n",
    "\n",
    "# 偽画像を生成\n",
    "input_z = torch.randn(2, 20)\n",
    "fake_images = G(input_z)\n",
    "\n",
    "# 偽画像をDに入力\n",
    "d_out, _ = D(fake_images, input_z)\n",
    "\n",
    "# 出力d_outにSigmoidをかけて0から1に変換\n",
    "print(nn.Sigmoid()(d_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YlRmvebQL8Kd"
   },
   "source": [
    "# Encoderの実装\n",
    "\n",
    "画像をzに変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ih6gWabsL8Kd"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3,\n",
    "                      stride=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        # 注意：白黒画像なので入力チャネルは1つだけ\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3,\n",
    "                      stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3,\n",
    "                      stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        # ここまでで画像のサイズは7×7になっている\n",
    "        self.last = nn.Linear(128 * 7 * 7, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "\n",
    "        # FCに入れるためにテンソルの形を整形\n",
    "        out = out.view(-1, 128 * 7 * 7)\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vun_KvShL8Kh",
    "outputId": "7234536c-2ce6-4c4e-e59b-b2ff071c6e7b"
   },
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "E = Encoder(z_dim=20)\n",
    "\n",
    "# 入力する画像データ\n",
    "x = fake_images  # fake_imagesは上のGで作成したもの\n",
    "\n",
    "# 画像からzをEncode\n",
    "z = E(x)\n",
    "\n",
    "print(z.shape)\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnwXk0a-L8Kl"
   },
   "source": [
    "# DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lXhlnQKL8Kl"
   },
   "outputs": [],
   "source": [
    "def make_datapath_list():\n",
    "    \"\"\"学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。 \"\"\"\n",
    "\n",
    "    train_img_list = list()  # 画像ファイルパスを格納\n",
    "\n",
    "    for img_idx in range(200):\n",
    "        img_path = \"./data/img_78_28size/img_7_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/img_78_28size/img_8_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "    return train_img_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffLPO9nJL8Kn"
   },
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \"\"\"画像の前処理クラス\"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pc4oS_UML8Kq"
   },
   "outputs": [],
   "source": [
    "class GAN_Img_Dataset(data.Dataset):\n",
    "    \"\"\"画像のDatasetクラス。PyTorchのDatasetクラスを継承\"\"\"\n",
    "\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''画像の枚数を返す'''\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''前処理をした画像のTensor形式のデータを取得'''\n",
    "\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)  # [高さ][幅]白黒\n",
    "\n",
    "        # 画像の前処理\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        return img_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfBEgPZUL8Ks",
    "outputId": "15bf560c-7348-455d-ffa3-20dd8f01f18b"
   },
   "outputs": [],
   "source": [
    "# DataLoaderの作成と動作確認\n",
    "\n",
    "# ファイルリストを作成\n",
    "train_img_list=make_datapath_list()\n",
    "\n",
    "# Datasetを作成\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "train_dataset = GAN_Img_Dataset(\n",
    "    file_list=train_img_list, transform=ImageTransform(mean, std))\n",
    "\n",
    "# DataLoaderを作成\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 動作の確認\n",
    "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "print(imges.size())  # torch.Size([64, 1, 64, 64])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9vLW5T6L8Ku"
   },
   "source": [
    "# 学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDF9_QozL8Kv"
   },
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(G, D, E, dataloader, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "\n",
    "    # 最適化手法の設定\n",
    "    lr_ge = 0.0001\n",
    "    lr_d = 0.0001/4\n",
    "    beta1, beta2 = 0.5, 0.999\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), lr_ge, [beta1, beta2])\n",
    "    e_optimizer = torch.optim.Adam(E.parameters(), lr_ge, [beta1, beta2])\n",
    "    d_optimizer = torch.optim.Adam(D.parameters(), lr_d, [beta1, beta2])\n",
    "\n",
    "    # 誤差関数を定義\n",
    "    # BCEWithLogitsLossは入力にシグモイド（logit）をかけてから、\n",
    "    # バイナリークロスエントロピーを計算\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "    # パラメータをハードコーディング\n",
    "    z_dim = 20\n",
    "    mini_batch_size = 64\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    G.to(device)\n",
    "    E.to(device)\n",
    "    D.to(device)\n",
    "\n",
    "    G.train()  # モデルを訓練モードに\n",
    "    E.train()  # モデルを訓練モードに\n",
    "    D.train()  # モデルを訓練モードに\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 画像の枚数\n",
    "    num_train_imgs = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        epoch_g_loss = 0.0  # epochの損失和\n",
    "        epoch_e_loss = 0.0  # epochの損失和\n",
    "        epoch_d_loss = 0.0  # epochの損失和\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-------------')\n",
    "        print('（train）')\n",
    "\n",
    "        # データローダーからminibatchずつ取り出すループ\n",
    "        for imges in dataloader:\n",
    "\n",
    "            # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
    "            if imges.size()[0] == 1:\n",
    "                continue\n",
    "\n",
    "            # ミニバッチサイズの1もしくは0のラベル役のテンソルを作成\n",
    "            # 正解ラベルと偽ラベルを作成\n",
    "            # epochの最後のイテレーションはミニバッチの数が少なくなる\n",
    "            mini_batch_size = imges.size()[0]\n",
    "            label_real = torch.full((mini_batch_size,), 1).to(device)\n",
    "            label_fake = torch.full((mini_batch_size,), 0).to(device)\n",
    "\n",
    "            # GPUが使えるならGPUにデータを送る\n",
    "            imges = imges.to(device)\n",
    "\n",
    "            # --------------------\n",
    "            # 1. Discriminatorの学習\n",
    "            # --------------------\n",
    "            # 真の画像を判定　\n",
    "            z_out_real = E(imges)\n",
    "            d_out_real, _ = D(imges, z_out_real)\n",
    "\n",
    "            # 偽の画像を生成して判定\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images, input_z)\n",
    "\n",
    "            # 誤差を計算\n",
    "            d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
    "            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            d_optimizer.zero_grad()\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 2. Generatorの学習\n",
    "            # --------------------\n",
    "            # 偽の画像を生成して判定\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images, input_z)\n",
    "\n",
    "            # 誤差を計算\n",
    "            g_loss = criterion(d_out_fake.view(-1), label_real)\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            g_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 3. Encoderの学習\n",
    "            # --------------------\n",
    "            # 真の画像のzを推定\n",
    "            z_out_real = E(imges)\n",
    "            d_out_real, _ = D(imges, z_out_real)\n",
    "\n",
    "            # 誤差を計算\n",
    "            e_loss = criterion(d_out_real.view(-1), label_fake)\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            e_optimizer.zero_grad()\n",
    "            e_loss.backward()\n",
    "            e_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 4. 記録\n",
    "            # --------------------\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            epoch_e_loss += e_loss.item()\n",
    "            iteration += 1\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f} ||Epoch_E_Loss:{:.4f}'.format(\n",
    "            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size, epoch_e_loss/batch_size))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "    print(\"総イテレーション回数:\", iteration)\n",
    "\n",
    "    return G, D, E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3o7-C9d7L8Kz",
    "outputId": "a0cdf3bd-089a-4879-f1d9-06968f870aa8"
   },
   "outputs": [],
   "source": [
    "# ネットワークの初期化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        # conv2dとConvTranspose2dの初期化\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # BatchNorm2dの初期化\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        # 全結合層Linearの初期化\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "# 初期化の実施\n",
    "G.apply(weights_init)\n",
    "E.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "print(\"ネットワークの初期化完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-eQCLPJL8K1",
    "outputId": "8b3e2089-8917-4987-a653-f0e760c3ad2d"
   },
   "outputs": [],
   "source": [
    "# 学習・検証を実行する\n",
    "# 15分ほどかかる\n",
    "num_epochs = 1500\n",
    "G_update, D_update, E_update = train_model(\n",
    "    G, D, E, dataloader=train_dataloader, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IL_pxhfEL8K5",
    "outputId": "c2240826-639b-44b5-9457-51f0f9f18cc5"
   },
   "outputs": [],
   "source": [
    "# 生成画像と訓練データを可視化する\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 入力の乱数生成\n",
    "batch_size = 8\n",
    "z_dim = 20\n",
    "fixed_z = torch.randn(batch_size, z_dim)\n",
    "G_update.eval()\n",
    "fake_images = G_update(fixed_z.to(device))\n",
    "\n",
    "# 訓練データ\n",
    "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "\n",
    "\n",
    "# 出力\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 上段に訓練データを\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 下段に生成データを表示する\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZKa9G-CZL8K7"
   },
   "source": [
    "# テスト画像で異常検知する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcB7w-4xL8K8"
   },
   "outputs": [],
   "source": [
    "# テスト用のDataLoaderの作成\n",
    "\n",
    "\n",
    "def make_test_datapath_list():\n",
    "    \"\"\"学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。 \"\"\"\n",
    "\n",
    "    train_img_list = list()  # 画像ファイルパスを格納\n",
    "\n",
    "    for img_idx in range(5):\n",
    "        img_path = \"./data/test_28size/img_7_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/test_28size/img_8_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/test_28size/img_2_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "    return train_img_list\n",
    "\n",
    "\n",
    "# ファイルリストを作成\n",
    "test_img_list = make_test_datapath_list()\n",
    "\n",
    "# Datasetを作成\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "test_dataset = GAN_Img_Dataset(\n",
    "    file_list=test_img_list, transform=ImageTransform(mean, std))\n",
    "\n",
    "# DataLoaderを作成\n",
    "batch_size = 5\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ua6uY7_L8K-",
    "outputId": "0fed73c2-783f-4e59-cd77-7b65bbf27930"
   },
   "outputs": [],
   "source": [
    "# テストデータの確認\n",
    "batch_iterator = iter(test_dataloader)  # イテレータに変換\n",
    "imges = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 上段に訓練データを\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OB-bso3WL8LB"
   },
   "outputs": [],
   "source": [
    "def Anomaly_score(x, fake_img, z_out_real, D, Lambda=0.1):\n",
    "\n",
    "    # テスト画像xと生成画像fake_imgのピクセルレベルの差の絶対値を求めて、ミニバッチごとに和を求める\n",
    "    residual_loss = torch.abs(x-fake_img)\n",
    "    residual_loss = residual_loss.view(residual_loss.size()[0], -1)\n",
    "    residual_loss = torch.sum(residual_loss, dim=1)\n",
    "\n",
    "    # テスト画像xと生成画像fake_imgを識別器Dに入力し、特徴量マップを取り出す\n",
    "\n",
    "    _, x_feature = D(x, z_out_real)\n",
    "    _, G_feature = D(fake_img, z_out_real)\n",
    "\n",
    "    # テスト画像xと生成画像fake_imgの特徴量の差の絶対値を求めて、ミニバッチごとに和を求める\n",
    "    discrimination_loss = torch.abs(x_feature-G_feature)\n",
    "    discrimination_loss = discrimination_loss.view(\n",
    "        discrimination_loss.size()[0], -1)\n",
    "    discrimination_loss = torch.sum(discrimination_loss, dim=1)\n",
    "\n",
    "    # ミニバッチごとに2種類の損失を足し算する\n",
    "    loss_each = (1-Lambda)*residual_loss + Lambda*discrimination_loss\n",
    "\n",
    "    # ミニバッチ全部の損失を求める\n",
    "    total_loss = torch.sum(loss_each)\n",
    "\n",
    "    return total_loss, loss_each, residual_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wl7OER2yL8LD",
    "outputId": "94ba7339-b73c-4b7e-d52e-e1dcb31909fb"
   },
   "outputs": [],
   "source": [
    "# 異常検知したい画像\n",
    "x = imges[0:5]\n",
    "x = x.to(device)\n",
    "\n",
    "# 教師データの画像をエンコードしてzにしてから、Gで生成\n",
    "E_update.eval()\n",
    "G_update.eval()\n",
    "z_out_real = E_update(imges.to(device))\n",
    "imges_reconstract = G_update(z_out_real)\n",
    "\n",
    "# 損失を求める\n",
    "loss, loss_each, residual_loss_each = Anomaly_score(\n",
    "    x, imges_reconstract, z_out_real, D_update, Lambda=0.1)\n",
    "\n",
    "# 損失の計算。トータルの損失\n",
    "loss_each = loss_each.cpu().detach().numpy()\n",
    "print(\"total loss：\", np.round(loss_each, 0))\n",
    "\n",
    "# 画像を可視化\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 上段に訓練データを\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 下段に生成データを表示する\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(imges_reconstract[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPOfqd1VL8LE"
   },
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6-4_EfficientGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
