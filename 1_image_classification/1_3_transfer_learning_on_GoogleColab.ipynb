{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UA1x5l3QlWqC"
   },
   "source": [
    "# 1.3「転移学習」で少量データの分類を実現する方法\n",
    "\n",
    "- 本ファイルでは、学習済みのVGGモデルを使用し、転移学習でアリとハチの画像を分類するモデルを学習します\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRJbymzfozM5"
   },
   "source": [
    "## 本ファイルは、Google Colabでの実行を前提としています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82UCc0cflWqI"
   },
   "source": [
    "# 学習目標\n",
    "\n",
    "1. 画像データからDatasetを作成できるようになる\n",
    "2. DataSetからDataLoaderを作成できるようになる\n",
    "3. 学習済みモデルの出力層を任意の形に変更できるようになる\n",
    "4. 出力層の結合パラメータのみを学習させ、転移学習が実装できるようになる\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJN48pwclWqJ"
   },
   "source": [
    "# 事前準備\n",
    "\n",
    "1. 書籍の指示に従い、本章で使用するデータをダウンロード\n",
    "\n",
    "2. forループの経過時間と残り時間を計測するパッケージtqdmをインストールします。\n",
    "\n",
    "conda install -c conda-forge tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWDnhY8Plo4P",
    "outputId": "9bf366b5-0c33-4f2f-a723-bcdc1f205d4d"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/YutaroOgawa/pytorch_advanced.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLva_hyUlxlf",
    "outputId": "1a9528d2-539a-4296-9edb-7793cdd0b464"
   },
   "outputs": [],
   "source": [
    "!ls\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dLafiH3l0v2",
    "outputId": "d3476745-7a8f-479f-caf3-42f1bc6a5377"
   },
   "outputs": [],
   "source": [
    "%cd \"pytorch_advanced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gw4aia4Dl3F2",
    "outputId": "1df93c9f-938b-4e8d-9f75-cbf721b02e30"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6LE69pul4zW",
    "outputId": "27b8663a-ebb5-4f09-d477-2d71cdd1d372"
   },
   "outputs": [],
   "source": [
    "%cd \"1_image_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YIxC8nkmLgB",
    "outputId": "59315278-1a73-4e23-e654-2c2aeb6ec5a5"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "teXfeIJxmMkw"
   },
   "outputs": [],
   "source": [
    "# make_folders_and_data_downloads.ipynbの中身を実行\r\n",
    "import os\r\n",
    "import urllib.request\r\n",
    "import zipfile\r\n",
    "\r\n",
    "\r\n",
    "data_dir = \"./data/\"\r\n",
    "if not os.path.exists(data_dir):\r\n",
    "    os.mkdir(data_dir)\r\n",
    "\r\n",
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\r\n",
    "save_path = os.path.join(data_dir, \"imagenet_class_index.json\")\r\n",
    "\r\n",
    "if not os.path.exists(save_path):\r\n",
    "    urllib.request.urlretrieve(url, save_path)\r\n",
    "\r\n",
    "url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\r\n",
    "save_path = os.path.join(data_dir, \"hymenoptera_data.zip\")\r\n",
    "\r\n",
    "if not os.path.exists(save_path):\r\n",
    "    urllib.request.urlretrieve(url, save_path)\r\n",
    "\r\n",
    "    # ZIPファイルを読み込み\r\n",
    "    zip = zipfile.ZipFile(save_path)\r\n",
    "    zip.extractall(data_dir)  # ZIPを解凍\r\n",
    "    zip.close()  # ZIPファイルをクローズ\r\n",
    "\r\n",
    "    # ZIPファイルを消去\r\n",
    "    os.remove(save_path)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4M1yJuxmVyp"
   },
   "outputs": [],
   "source": [
    "# 追記以上--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Nk2_bfilWqJ"
   },
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import glob\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsQFy7nflWqK"
   },
   "outputs": [],
   "source": [
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0wuE1LQlWqK"
   },
   "source": [
    "# DataSetを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PerlS6ilWqK"
   },
   "outputs": [],
   "source": [
    "# 入力画像の前処理をするクラス\n",
    "# 訓練時と推論時で処理が異なる\n",
    "\n",
    "\n",
    "class ImageTransform():\n",
    "    \"\"\"\n",
    "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
    "    画像のサイズをリサイズし、色を標準化する。\n",
    "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    resize : int\n",
    "        リサイズ先の画像の大きさ。\n",
    "    mean : (R, G, B)\n",
    "        各色チャネルの平均値。\n",
    "    std : (R, G, B)\n",
    "        各色チャネルの標準偏差。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(\n",
    "                    resize, scale=(0.5, 1.0)),  # データオーギュメンテーション\n",
    "                transforms.RandomHorizontalFlip(),  # データオーギュメンテーション\n",
    "                transforms.ToTensor(),  # テンソルに変換\n",
    "                transforms.Normalize(mean, std)  # 標準化\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(resize),  # リサイズ\n",
    "                transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\n",
    "                transforms.ToTensor(),  # テンソルに変換\n",
    "                transforms.Normalize(mean, std)  # 標準化\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase='train'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase : 'train' or 'val'\n",
    "            前処理のモードを指定。\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "mnzGcMN_lWqL",
    "outputId": "f7d4f271-7c1f-4028-a5fe-9c1d1721218d"
   },
   "outputs": [],
   "source": [
    "# 訓練時の画像前処理の動作を確認\n",
    "# 実行するたびに処理結果の画像が変わる\n",
    "\n",
    "# 1. 画像読み込み\n",
    "image_file_path = './data/goldenretriever-3724972_640.jpg'\n",
    "img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "\n",
    "# 2. 元の画像の表示\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# 3. 画像の前処理と処理済み画像の表示\n",
    "size = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "transform = ImageTransform(size, mean, std)\n",
    "img_transformed = transform(img, phase=\"train\")  # torch.Size([3, 224, 224])\n",
    "\n",
    "# (色、高さ、幅)を (高さ、幅、色)に変換し、0-1に値を制限して表示\n",
    "img_transformed = img_transformed.numpy().transpose((1, 2, 0))\n",
    "img_transformed = np.clip(img_transformed, 0, 1)\n",
    "plt.imshow(img_transformed)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3gJ3XmJlWqM",
    "outputId": "23617ca5-dd0c-4bba-bfd7-e41fc270607e"
   },
   "outputs": [],
   "source": [
    "# アリとハチの画像へのファイルパスのリストを作成する\n",
    "\n",
    "\n",
    "def make_datapath_list(phase=\"train\"):\n",
    "    \"\"\"\n",
    "    データのパスを格納したリストを作成する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phase : 'train' or 'val'\n",
    "        訓練データか検証データかを指定する\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    path_list : list\n",
    "        データへのパスを格納したリスト\n",
    "    \"\"\"\n",
    "\n",
    "    rootpath = \"./data/hymenoptera_data/\"\n",
    "    target_path = osp.join(rootpath+phase+'/**/*.jpg')\n",
    "    print(target_path)\n",
    "\n",
    "    path_list = []  # ここに格納する\n",
    "\n",
    "    # globを利用してサブディレクトリまでファイルパスを取得する\n",
    "    for path in glob.glob(target_path):\n",
    "        path_list.append(path)\n",
    "\n",
    "    return path_list\n",
    "\n",
    "\n",
    "# 実行\n",
    "train_list = make_datapath_list(phase=\"train\")\n",
    "val_list = make_datapath_list(phase=\"val\")\n",
    "\n",
    "train_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADiGymTSlWqM",
    "outputId": "02e26af1-1b30-4634-a5fb-0bf4901fc8a8"
   },
   "outputs": [],
   "source": [
    "# アリとハチの画像のDatasetを作成する\n",
    "\n",
    "\n",
    "class HymenopteraDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    アリとハチの画像のDatasetクラス。PyTorchのDatasetクラスを継承。\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file_list : リスト\n",
    "        画像のパスを格納したリスト\n",
    "    transform : object\n",
    "        前処理クラスのインスタンス\n",
    "    phase : 'train' or 'test'\n",
    "        学習か訓練かを設定する。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_list, transform=None, phase='train'):\n",
    "        self.file_list = file_list  # ファイルパスのリスト\n",
    "        self.transform = transform  # 前処理クラスのインスタンス\n",
    "        self.phase = phase  # train or valの指定\n",
    "\n",
    "    def __len__(self):\n",
    "        '''画像の枚数を返す'''\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        前処理をした画像のTensor形式のデータとラベルを取得\n",
    "        '''\n",
    "\n",
    "        # index番目の画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)  # [高さ][幅][色RGB]\n",
    "\n",
    "        # 画像の前処理を実施\n",
    "        img_transformed = self.transform(\n",
    "            img, self.phase)  # torch.Size([3, 224, 224])\n",
    "\n",
    "        # 画像のラベルをファイル名から抜き出す\n",
    "        if self.phase == \"train\":\n",
    "            label = img_path[30:34]\n",
    "        elif self.phase == \"val\":\n",
    "            label = img_path[28:32]\n",
    "\n",
    "        # ラベルを数値に変更する\n",
    "        if label == \"ants\":\n",
    "            label = 0\n",
    "        elif label == \"bees\":\n",
    "            label = 1\n",
    "\n",
    "        return img_transformed, label\n",
    "\n",
    "\n",
    "# 実行\n",
    "train_dataset = HymenopteraDataset(\n",
    "    file_list=train_list, transform=ImageTransform(size, mean, std), phase='train')\n",
    "\n",
    "val_dataset = HymenopteraDataset(\n",
    "    file_list=val_list, transform=ImageTransform(size, mean, std), phase='val')\n",
    "\n",
    "# 動作確認\n",
    "index = 0\n",
    "print(train_dataset.__getitem__(index)[0].size())\n",
    "print(train_dataset.__getitem__(index)[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6M2pUtcklWqN"
   },
   "source": [
    "# DataLoaderを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-TwF8UealWqN",
    "outputId": "8c0a5ed3-8a7d-407c-bb72-0cc4be80648f"
   },
   "outputs": [],
   "source": [
    "# ミニバッチのサイズを指定\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoaderを作成\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "\n",
    "# 動作確認\n",
    "batch_iterator = iter(dataloaders_dict[\"train\"])  # イテレータに変換\n",
    "inputs, labels = next(\n",
    "    batch_iterator)  # 1番目の要素を取り出す\n",
    "print(inputs.size())\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDdKxowclWqN"
   },
   "source": [
    "# ネットワークモデルの作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "referenced_widgets": [
      "350e40ad89fd4b289557201d12bd1878",
      "44a3efe233ad48699e9f59747f120f8d",
      "241cd1502c7c473ca0f525562f268c92",
      "96edb32a99d04f7d8bb9f161a699d4d3",
      "1b891dddf11343e696e5fd695c5a71df",
      "bc11034b13794c8db6b5dc2f4543932a",
      "d6b27aef63334910b4ec0b78b666684d",
      "af72d2b92986469d8abb55ab7b2ca180"
     ]
    },
    "id": "AsfGZ9B7lWqO",
    "outputId": "d7c303e3-b1e8-4229-ab39-c209cb820410"
   },
   "outputs": [],
   "source": [
    "# 学習済みのVGG-16モデルをロード\n",
    "# VGG-16モデルのインスタンスを生成\n",
    "use_pretrained = True  # 学習済みのパラメータを使用\n",
    "net = models.vgg16(pretrained=use_pretrained)\n",
    "\n",
    "# VGG16の最後の出力層の出力ユニットをアリとハチの2つに付け替える\n",
    "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
    "\n",
    "# 訓練モードに設定\n",
    "net.train()\n",
    "\n",
    "print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8rap7ISlWqO"
   },
   "source": [
    "# 損失関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wiJCU6VlWqO"
   },
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kt3ziuoUlWqO"
   },
   "source": [
    "# 最適化手法を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxkNa9LvlWqP",
    "outputId": "a480e08e-674e-45c3-c95d-b8c2ff848608"
   },
   "outputs": [],
   "source": [
    "# 転移学習で学習させるパラメータを、変数params_to_updateに格納する\n",
    "params_to_update = []\n",
    "\n",
    "# 学習させるパラメータ名\n",
    "update_param_names = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
    "\n",
    "# 学習させるパラメータ以外は勾配計算をなくし、変化しないように設定\n",
    "for name, param in net.named_parameters():\n",
    "    if name in update_param_names:\n",
    "        param.requires_grad = True\n",
    "        params_to_update.append(param)\n",
    "        print(name)\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# params_to_updateの中身を確認\n",
    "print(\"-----------\")\n",
    "print(params_to_update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDfKFIDglWqP"
   },
   "outputs": [],
   "source": [
    "# 最適化手法の設定\n",
    "optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ocQ2VbJlWqP"
   },
   "source": [
    "# 学習・検証を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXgRLEXHlWqP"
   },
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)  # 損失を計算\n",
    "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "                    \n",
    "  \n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # イタレーション結果の計算\n",
    "                    # lossの合計を更新\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  \n",
    "                    # 正解数の合計を更新\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # epochごとのlossと正解率を表示\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double(\n",
    "            ) / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i0cuPPsxlWqQ",
    "outputId": "202ca950-75c7-4236-b7e1-b7cd3e55b688"
   },
   "outputs": [],
   "source": [
    "# 学習・検証を実行する\n",
    "num_epochs=2\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NRfoFSZlWqQ"
   },
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1-3_transfer_learning_on_GoogleColab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
